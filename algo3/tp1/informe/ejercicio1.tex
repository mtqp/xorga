\begin{section}{Problema 1}

	\textit{Dados $b,n \in \mathbb{N} $ calcular $b^n\; mod\; n$}

	\begin{subsection}{Explicación}

		Una solución factible al problema es utilizar un algoritmo recursivo basado en la técnica $Divide\; \&\; Conquer$. La idea sería quedarnos cada vez con un problema más chico, dividiendo el exponente a la mitad y resolver recursivamente dicho problema hasta llegar a uno suficientemente chico (en este caso cuando el exponente sea 2) para luego combinar las soluciones elevando al cuadrado lo ya calculado y obtener así una solución al problema original. En el caso donde $n$ fuese impar se resuelve el problema para $n-1$ a través del procedimiento mencionado y luego se multiplica el resultado por $b$.

		Para la resolución del problema decidimos utilizar un algoritmo iterativo frente a uno recursivo debido al uso que este último hace de la pila, lo cual implica repetidos accesos a memoria que disminuyen la performance del algoritmo, y la posibilidad de {\em stack overflow}.

		La versión iterativa de la solución funciona de la siguiente manera: en cada iteración el algoritmo divide el exponente a la mitad y eleva al cuadrado $b$. Cuando llega a un exponente impar, multiplica el resultado parcial (en la primer iteración 1) por $b$. Cuando el exponente es 0, termina, siendo el resultado parcial el valor del resultado final. Es decir, el resultado es la productoria de los resultados parciales obtenidos en los exponentes impares. Al acumular en $b$ las potencias calculadas el algoritmo evita repetir cálculos y logra disminuir la cantidad de multiplicaciones.

		Tanto la versión recursiva como la iterativa toman módulo $n$ luego de cada multiplicación para asegurarse que el resultado entra en el tamaño de la variable (suponiendo que $(n-1)\times (n-1)$ entra).
	\end{subsection}
	
	\begin{subsection}{Detalles de la implementación}
		\begin{itemize}
			\item La función recibe como parámetros por copia $n$ y $b$.
			\item El resultado parcial de la función se guarda en la variable $tmp$, inicializada en 1.
			\item \textbf{Caso base:} 
			\begin{itemize}
				\item Cuando $n$ es menor que 3, entra al caso base $b<2$ ya que al comienzo la función toma $b=b\;mod\; n$ ($b\; mod\; 1 = 0$ y $b\; mod\; 2$  es $cero$ si b es par y $uno$ si es impar) 
				\item Cuando $b$ es $uno$ o $cero$, entra al caso base $b<2$ y el resultado es $b$ (porque $1^n\;mod\;n=1$ y $0^n\;mod\;n=0$).
			\end{itemize}

			\item Antes de iniciar el ciclo, se crea una copia ($m$) de $n$ para preservar su valor original.

			\item \textbf{Ciclo:}
			\begin{itemize}
				
				\item \textbf{Caso condicional:} si $m$ es impar multiplicamos $tmp$ por el valor de $b$.
				
				\item \textbf{En cada iteración:}
				\begin{itemize}
					\item Se divide a la mitad $m$ tomando la parte entera.
					\item Se eleva al cuadrado $b$.
				\end{itemize}

				\item Luego de cada multiplicación toma módulo $n$ ya que
				$$b^k * b^{n-k}\; mod\;n = ((b^k\;mod\;n)*(b^{n-k}\;mod\;n))\;mod\;n\;\forall\;k\leq n ^{[*]}$$ 
	
				De esta manera, incluso si el cálculo de $b^n$ es un número tan grande que no entra en el 
				tamaño de la variable, se va a poder realizar sin problemas (suponiendo que $(n-1)^2$ entra 
				en una variable).

			\end{itemize}
		\end{itemize}
		
		\vspace{0.5cm}
		{\footnotesize [*] Por propiedades del módulo $x*y\; mod \; z = ((x\; mod\; z)*(y\; mod\; z))\;mod\; z$ } \\
		
	\end{subsection}



	\begin{subsection}{Análisis de complejidad}
		Elegimos el modelo logarítmico para analizar el algoritmo, ya que las operaciones que aplicamos dependen del logaritmo de $n$, o dicho de otra forma, del tamaño de la entrada. No obstante, en los resultados muchas de ellas tienen costo uniforme por trabajar con números de tamaño acotado (\texttt{unsigned long long int}) para simplificar la implementación.\Pa

		Sea $m = n$ y $tmp$ inicializado en $1$.\\

		Como $b\leq n$ y la función logaritmo es estrictamente creciente, $\log b \leq \log n$. De la misma manera, $\log tmp$ está acotado por $\log n$.\\

		Sean las siguientes complejidades en el modelo logarítmico:\\

		\vspace{0.5cm}
		\begin{pseudo}
			\func{bn\_mod\_n}{$b,n$}
			\tab\WHILE{$m>0$} \\
			\tab\tab \IF{ $m$ es impar } & \tOde{\log m} \\
			\tab\tab \tab $tmp \leftarrow tmp * b$ & \tOde{\log^{2}n} \\
			\tab\tab \tab $tmp \leftarrow tmp\; mod\; n$ & \tOde{\log^{2}n} \\
			\tab\tab $m \leftarrow \frac{m}{2}$ & \tOde{\log m} \\
			\tab\tab $b \leftarrow b^2$ & \tOde{\log^{2} n} \\
			\tab\tab $b \leftarrow b\; mod \; n$ & \tOde{\log^{2} n} \\
			\tab\RET $tmp$ \\
		\end{pseudo} \\

		Analizaremos a continuación la cantidad de operaciones, complejidad en el modelo logarítmico y complejidad en función del tamaño de la entrada.

		\begin{subsubsection}{Cantidad de operaciones}
			Para determinar la cantidad de operaciones que realiza el algoritmo\\ analizamos el valor $m$ en cada iteración debido a que la cantidad de iteraciones
			del ciclo depende de cuántas veces sea necesario dividir a $m$ a la mitad para que sea igual a 0.

			\begin{center}
			\begin{tabular}{rlcl}
				1er&iteración & $\rightarrow$ & $m = n$ \\
				2da&iteración & $\rightarrow$ & $m = \frac{n}{2}$ \\
				3er&iteración & $\rightarrow$ & $m = \frac{n}{2^2}$ \\
				4ta&iteración & $\rightarrow$ & $m = \frac{n}{2^3}$ \\
				&\vdots&&\vdots \\
				$k$-ésima&iteración & $\rightarrow$ & $m = \frac{n}{2^{k-1}} = 1$  
			\end{tabular}
			\end{center}

			\noindent Como el ciclo termina cuando $m=0$, en la última iteración $m=1$. Por lo tanto, hallamos $k$ tal que $m=1$ para así obtener la cantidad total de iteraciones:
			\begin{eqnarray*}
				\frac{n}{2^{k-1}}&=& 1 \\
				n &=& 2^{k-1} \\
				\log n &=& \log\; 2^{k-1} \\
				\log n &=& k-1 \Rightarrow k = \log( n )+1
			\end{eqnarray*}

			\noindent es decir, el algoritmo hace $\log(n)+1$ iteraciones, cada una con una cantidad de operaciones acotadas por una constante $c$. La cantidad máxima de
			operaciones se da en las iteraciones en las que $m$ es impar porque entra al caso condicional. Luego, la cantidad de operaciones que hace el algoritmo es $c*((\log n)+1)$.
			Por lo tanto, la cantidad de operaciones es del orden de $\log n$ y \Ode{\log n} $\subset$ \Ode{n}.

		\end{subsubsection}


		\begin{subsubsection}{Complejidad en el modelo logarítmico}

			Como $m\leq n$ y la función logaritmo es estrictamente creciente, $\log m \leq \log n$. De la misma manera, $\log b$ y $\log tmp$ están acotados por $\log n$. Por lo tanto, la complejidad en el modelo logarítmico es: \\
			\Ode{\log(n)*(\log(n)+\log^2(n)+\log^2(n)+\log(n)+\log^2(n)+\log^2(n))} $=$ \\
			$=$ \Ode{\log(n)*(2\log(n)+4\log^2(n))} $=$ \Ode{2\log^2 n + 4\log^3 n} \\

			Luego, por definición, 
			\begin{center}
				\Ode{2\log^2 n + 4\log^3 n} $=$ \Ode{\max(2\log^2 n , 4\log^3 n)} $=$ \Ode{\log^3 n}.
			\end{center}

			Entonces, la complejidad del algoritmo resulta ser: \Ode{log^3 n}
		
		\end{subsubsection}


		\begin{subsubsection}{Complejidad en función del tamaño de la entrada}
			El tamaño de la entrada $t$ es $\log n$ ya que $b$ es acotado ($n=2^t$). Entonces la complejidad del algoritmo en función del tamaño de entrada es: \Ode{\log^3
			2^t}=\Ode{t^3}. El algoritmo es polinomial.
		\end{subsubsection}

	\end{subsection}
	\begin{subsection}{Pruebas y Resultados}
		Para probar correctitud tenemos un generador de instancias random que nos devuelve dos archivos, en uno \texttt{test.in} la instancia elegida ($b$ $n$) y otro \texttt{test.out} el resultado ($b^n \mod n$). De esta forma, con una comparación de archivos (comando \texttt{diff test.out bn\_mod\_n.out} ) podemos saber para cada instancia si el resultado obtenido por nuestro algoritmo se condice con el resultado correspondiente a esa instancia en el archivo \texttt{test.out}.
		
		Para llevar a cabo las pruebas de este algoritmo en cuanto a operaciones realizadas por instancia, y tiempo en segundos transcurridos, generamos números en forma aleatoria, con $b$ comprendido entre $0$ y $200$ (porque $b$ está acotado), y $n$ entre 1 y $10^7$ (ya que esta cantidad de instancias posibles permite contrastar el comportamiento del algoritmo con los resultados teóricos).

En los siguientes gráficos cada instancia está representada con {\color{red}+}. También está representada en color verde la función $log(n)*c$, ya que es la cota teórica previamente calculada con una constante aproximada calculada empíricamente para cada gráfico. A continuación se muestra la cantidad de operaciones realizadas en función de $n$ (donde $c$ es $19$).\VSP

		\gra{bn_mod_n/count_test}\VSP
		
		\newpage

El siguiente gráfico muestra el tiempo transcurrido (en segundos) en función de $n$ (donde $c$ es $1.15*10^{-7}$)\VSP

		\gra{bn_mod_n/time_test}

En los gráficos anteriores se ve cómo la cantidad de operaciones y el tiempo que tardó en ejecutar cada instancia están acotados por la función logaritmo (multiplicada por la constante correspondiente en cada caso), con $n$ como parámetro. Los casos cercanos al cero en los ejes que representan al tiempo y la cantidad de operaciones, co\-rres\-pon\-den al caso trivial del ejercicio (caso base), en los que no hubo necesidad de iterar para llegar al resultado.

		Como medir el tiempo no es una herramienta muy precisa, se pueden ver algunos {\em outliers} por encima de la curva del logaritmo. Aun así, los resultados coinciden con las predicciones en cuanto a la complejidad.\Pa

En el siguiente gráfico se muestran instancias en las que en cada iteración entra al caso condicional junto con las instancias que en ninguna de las iteraciones entra al caso condicional. Las instancias fueron generadas de la siguiente manera:
\begin{itemize}
	\item En ambos casos se tomó $2 < b < 200$ aleatoriamente. El valor máximo es $200$ ya que $b$ está acotado y el valor mínimo fue elegido para evitar generar casos base y así poder ver únicamente los casos en cuestión.
	\item Para las instancias que entran siempre al caso condicional se eligieron los $n$ dados por $2^i-1\;\;\forall\; i\in\mathbb{N}, 2 < i < 31$ debido a que al hacer la división entera de $n$ por $2$, siempre se obtiene un nuevo $n$ impar. Esto hace que sea el peor caso. Elegimos $31$ como cota superior para $i$ porque es el máximo valor tal que $2^{31} \times 2^{31}$ entra en la variable y $2$ como cota inferior para evitar los casos bases.
	\item Para las instancias que nunca entran al caso condicional se eligieron los $n$ dados por $2^i\;\;\forall\; i\in\mathbb{N}, 2 < i < 31$ debido a que al hacer la división entera de $n$ por $2$, siempre se obtiene un nuevo $n$ par. Esto hace que sea el mejor caso excluyendo los casos base. La cota para $i$ fue elegida con el mismo criterio que para generar los $n$ impares.
\end{itemize}

	Con esta prueba se espera poder contrastar ambos casos. Tanto el mejor como el peor caso difieren en una constante que se desprecia en la complejidad teórica pero que en la práctica puede significar una diferencia de rendimiento importante a medida que $n$ crece.

El eje del gráfico que corresponde al valor de $n$ está en escala logarítmica para poder apreciar mejor el gráfico dado que los valores de $n$ tomados crecen exponencialmente. Cada instancia que entra siempre al caso condicional está representada con {\color{red}+}. A su vez, las instancias que nunca entran al caso condicional están representadas con {\color{blue}+}. También está graficada en color verde la función $log(n)*19+15$, ya que es la cota teórica previamente calculada con una constante aproximada calculada empíricamente.\VSP

		\gra{bn_mod_n/count_test_if}\VSP

Observamos en el gráfico que para cada $n$ impar elegido, hay un $n$ par consecutivo. Cuanto mayor es $n$, mayor es la diferencia entre la cantidad de operaciones entre esas dos instancias. Esto se debe a que dichos $n$ impares corresponden al peor caso del algoritmo y los pares al mejor. Asintóticamente, la diferencia entre mejor y peor caso resulta significativa a la hora del procesamiento.

\texttt{Observación:}
Notamos que los resultados correspondientes a las instancias que nuncan entran al caso condicional son siempre $uno$ o $cero$. Más específicamente el resultado es siempre $cero$ para una instancia con $b$ par y siempre $uno$ para una instancia con $b$ impar.\VSP
	\end{subsection}

	\begin{subsection}{Conclusiones}
		En este ejercicio nos encontramos con un problema donde debíamos\\ operar valores enteros muy grandes, esto hizo que no pudiésemos considerar constante el costo de las operaciones elementales. Tuvimos así que analizar la complejidad en el modelo logarítmico. Al analizarla, tuvimos que diferenciarla en función de $n$ y del tamaño de entrada (lo que se hizo en todos los ejercicios), con la particularidad de que en función de $n$ resultó logarítmico, y en función del tamaño de la entrada, polinomial.

		Las mediciones de tiempo y cantidad de operaciones se correspondieron con las complejidades teóricas calculadas. Esto indica que el modelo elegido fue adecuado.

		Además, pudimos observar que en este caso la limitación del algoritmo no está dada por el tiempo de ejecución sino por el rango de valores admitidos ya que a partir de cierto $n$ hay que trabajar con números más grandes de lo que se puede almacenar en la variable. Dicho esto, nos parece un buen algoritmo porque como cualquier otro que opera con variables numéricas en algún punto hace $overflow$ para una entrada 'suficientemente grande', y este puede devolver un resultado para todas las instancias -donde esto no ocurre- con un costo temporal muy bajo.
	\end{subsection}
\end{section}

